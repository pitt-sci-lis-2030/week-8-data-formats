{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 8 Lecture - Data Formats\n",
    "\n",
    "Topics\n",
    "* Review importing libraries\n",
    "* Review CSV\n",
    "* JSON Data Format\n",
    "* XML Data Format\n",
    "* JSON and Python\n",
    "* Parsing MARC records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "Python has some functions already loaded and ready to use (like `print()`, `len()`, `type()` and `range()`. The full list of built-in functions can be found [on the Python Documentation website](https://docs.python.org/3/library/functions.html).\n",
    "\n",
    "Beyond the built-in functions, Python has a very extensive [standard library](https://docs.python.org/3/library/index.html), which provides additional functionality in a variety of areas including [math](https://docs.python.org/3/library/numeric.html), [text processing](https://docs.python.org/3/library/text.html), and working with unique [file formats](https://docs.python.org/3/library/fileformats.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the time module from the standard library\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the [time module](https://docs.python.org/3/library/time.html) to see how many nanoseconds have elapsed since the [EPOCH](https://en.wikipedia.org/wiki/Unix_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many nanoseconds\n",
    "time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When is the EPOCH (on this computer)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the gmtime method to see whehn is time point zero\n",
    "time.gmtime(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The world (of computers) is only 51 years old."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing CSV files\n",
    "\n",
    "* CSV stands for *comma separated values* \n",
    "* Is a file format for tabular data, i.e. Excel Spreadsheets\n",
    "* It is a pretty common data format\n",
    "* So Python has a built-in parser in the [CSV module](https://docs.python.org/3/library/csv.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv module into memory\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the dog names csv file and loop over the contents\n",
    "with open(\"files/pgh-dog-names.csv\", \"r\") as fileh:\n",
    "    # create the special csv reader object that knows how to parse the file\n",
    "    csv_reader = csv.reader(fileh)\n",
    "    \n",
    "    # initialize a variable with a very short name\n",
    "    long_name = \"\"\n",
    "    breed = \"\"\n",
    "    color = \"\"\n",
    "\n",
    "    # loop over each line look for the longest dog name\n",
    "    for dog in csv_reader:\n",
    "        # the name is the 4th column\n",
    "        # check to see if that string is longer than long_name\n",
    "        if len(dog[3]) > len(long_name):\n",
    "            # if we have a new long name, save it in the variable long_name\n",
    "            long_name = dog[3]\n",
    "            breed = dog[1]\n",
    "            color = dog[2]\n",
    "\n",
    "\n",
    "# print the name of the dog with the longest name\n",
    "print(\"The dog with the longest name in Pittsburgh is\", long_name)\n",
    "print(\"It is a\", color, breed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These data fit nicely into a two dimensional table, but sometimes you have data that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![json slide](json-slides/Slide2.png)\n",
    "![json slide](json-slides/Slide3.png)\n",
    "![json slide](json-slides/Slide4.png)\n",
    "![json slide](json-slides/Slide5.png)\n",
    "![json slide](json-slides/Slide6.png)\n",
    "![json slide](json-slides/Slide7.png)\n",
    "![json slide](json-slides/Slide8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is XML?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![json slide](json-slides/Slide9.png)\n",
    "![json slide](json-slides/Slide10.png)\n",
    "![json slide](json-slides/Slide11.png)\n",
    "![json slide](json-slides/Slide12.png)\n",
    "![json slide](json-slides/Slide13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing JSON and Python\n",
    "\n",
    "Python is *batteries included* so there is already a [JSON module](https://docs.python.org/3/library/json.html) in the standard library.\n",
    "\n",
    "The JSON module provides 4 main functions. Two for decoding (parsing) and two for encoding (*serializing*):\n",
    "* `json.load()` - Parse JSON data from a file\n",
    "* `json.loads()` - Parse JSON data from a string\n",
    "* `json.dump()` - Serialize Python data into a JSON file\n",
    "* `json.dumps()` - Serialize Python data into a JSON string\n",
    "\n",
    "Notice a pattern on the naming convention?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding / Parsing JSON data\n",
    "\n",
    "I have included some fun JSON data in the `files` folder. Let's go and see what we have using JupyterLab and then open them with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = \"\"\"\n",
    "{\"something\":\"I was not able to think of any fun data\", \n",
    "\"data\":[1,2,3,4,5,6]}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "parsed_json = json.loads(json_string)\n",
    "parsed_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What *type* is this parsed data being represented in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(parsed_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON maps very nicely to Python dictionaries. You can see how the JSON data types map to Python data types in [the documentation](https://docs.python.org/3/library/json.html#encoders-and-decoders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually we don't type our json literally as strings...we store it in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open a JSON file handler and parse it into a python d\n",
    "with open(\"files/stranger.json\") as fileh:\n",
    "    stranger_data = json.load(fileh) #stranger danger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the data\n",
    "stranger_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value at the key summary\n",
    "stranger_data['summary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Python dictionary indexing, we can reach into this complex data structure and grab subsets of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many episodes\n",
    "len(stranger_data[\"_embedded\"][\"episodes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, we have to have a pre-existing understanding of the data structure so we can know what keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding / Serializing JSON Data\n",
    "\n",
    "From the [Rick and Morty API](https://rickandmortyapi.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"files/rm-characters.json\") as fileh:\n",
    "    rm_characters = json.load(fileh)\n",
    "rm_characters[\"info\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rm_characters[\"results\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have twenty characters, but maybe we just want to have the aliens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dictionary for our data\n",
    "aliens = {}\n",
    "\n",
    "# loop over all the characters\n",
    "for character in rm_characters[\"results\"]:\n",
    "    # check to see if the character is an alient\n",
    "    if character[\"species\"] == \"Alien\":\n",
    "        #using the name as a key, save the data for alien characters as values\n",
    "        aliens[character[\"name\"]] = character\n",
    "\n",
    "# display the results\n",
    "aliens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our data to disk\n",
    "with open(\"aliens.json\", \"w\") as fileh:\n",
    "    json.dump(aliens, fileh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ancient aliens](https://i.kym-cdn.com/photos/images/original/000/183/103/alens.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dictionary for our data\n",
    "aliens = []\n",
    "\n",
    "# loop over all the characters\n",
    "for character in rm_characters[\"results\"]:\n",
    "    # check to see if the character is an alient\n",
    "    if character[\"species\"] == \"Alien\":\n",
    "        #using the name as a key, save the data for alien characters as values\n",
    "        aliens.append(character)\n",
    "\n",
    "# display the results\n",
    "aliens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"aliens.json\", \"w\") as fileh:\n",
    "    json.dump(aliens, fileh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to get all this data as a JSON string, we can use `dumps`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing MARC records\n",
    "\n",
    "Unfortunately, [MARC records are still a thing](https://www.libraryjournal.com/?detailStory=marc-must-die) and so we need to *deal with it*.\n",
    "\n",
    "Double Unfortunately, Python does not include a MARC parser as part of the standard library.\n",
    "\n",
    "![batteries not included](https://images-na.ssl-images-amazon.com/images/I/71uIJYNfJZL._SL1500_.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, [a brave soul](https://inkdroid.org/about/) has built this capacity for us in the form of a third-party library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with pymarc library for this lecture.  Details about it can be found [here](https://gitlab.com/pymarc/pymarc), which also has some documentation and resources for its use.  There is also a complete library documentation [here](https://readthedocs.org/projects/pymarc/downloads/pdf/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing 3rd party libraries\n",
    "\n",
    "Libraries like Pymarc are not part of the \"standard library,\" which means you have to install them on your computer yourself. There are currently 291,647 on the [PyPI website](https://pypi.org), the Python Package Index, a repository of 3rd party packages. You don't need to install all of them, only the ones you need.\n",
    "\n",
    "In our case, we needed to install the [pymarc](https://pypi.org/project/pymarc/) package. \n",
    "\n",
    "\n",
    "\n",
    "Installing packages is done using a command line tool called `pip` and you can run the code cell below to execute a unix command to install pymarc. NOTE: this may not work on Windows computers AND you don't need to run this if you are on JupyterHub (it just won't do anything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the command pip to install pymarc\n",
    "!pip install pymarc --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that pymarc is installed, we can `import` it like any other library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the \n",
    "import pymarc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading MARC files\n",
    "\n",
    "MARC files are text files (technically they are MARC8 encoded text files) and they are UGLY. But because they are just text you can open them using the regular Python file machinery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open MARC file called marc.dat\n",
    "with open(\"files/marc.dat\", 'r') as raw:\n",
    "    print(raw.read(3000)) #read first 1000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot going on in that file and parsing it using Python string methods would be unpleasant. Because somoene did that for us, we can stand on the shoulder of giants!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty list to store the records\n",
    "marc_records = []\n",
    "\n",
    "# open the file \n",
    "with open(\"files/marc.dat\", \"rb\") as fileh:\n",
    "    \n",
    "    # create an isntance of the marc reader, like with CSV \n",
    "    marc_reader = pymarc.MARCReader(fileh)\n",
    "    \n",
    "    # loop over each record\n",
    "    for record in marc_reader:\n",
    "        # add record to our list\n",
    "        marc_records.append(record)\n",
    "        \n",
    "print(\"There are\", len(marc_records), \"MARC records.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a record look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the 2nd record at index 1 because...\n",
    "marc_records[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drat! What we are looking at is an complex, custom data structure (technically an \"object\") of the type `Record`. We won't get into the details of object oriented programming. \n",
    "\n",
    "If we want to manipulate are Record, we should [read the documentation](https://pymarc.readthedocs.io/en/latest/#module-pymarc.record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see what the dictionary representation of the MARC record\n",
    "marc_records[1].as_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh, still a mess, but we can use handy methods like `title()` and `author()` to grab information without having to memorize MARC fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each record\n",
    "for record in marc_records:\n",
    "    # print name and author\n",
    "    print(record.title(), \"by\", record.author())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pymarc includes a bunch of helper functions for grabbing information from a MARC record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the ISBN \n",
    "marc_records[11].isbn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dispay the publisher \n",
    "marc_records[12].publisher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the publication year\n",
    "marc_records[1].pubyear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the subjects\n",
    "marc_records[-4].subjects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AH! We have a list of [Fields](https://pymarc.readthedocs.io/en/latest/#module-pymarc.field), we need to do some looping and reading of documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each field and display the field value\n",
    "for subject in marc_records[-4].subjects() :\n",
    "    print(subject.value())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each field and display the raw MARC\n",
    "for subject in marc_records[-4].subjects() :\n",
    "    print(subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are wicked smart and have memorized the MARC field numbers by heart, you can always reference them directly using Python indexing syntax. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value for field 300 from\n",
    "marc_records[1]['300'].value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the 245 field in the original MARC format\n",
    "marc_records[1]['245'].as_marc(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new blank MARC record\n",
    "record = pymarc.Record() \n",
    "\n",
    "# Create the 245 and 100 fields \n",
    "title = pymarc.Field(\n",
    "        tag = '245',\n",
    "        indicators = ['0','1'], \n",
    "        subfields = [\n",
    "            'a', 'The Beaverkill : ', 'b', 'The History of a Rever and its People /'\n",
    "        ])\n",
    "author = pymarc.Field(\n",
    "        tag = '100',\n",
    "        indicators = ['0','1'], \n",
    "        subfields = [\n",
    "            'a', 'Ed Van Put'\n",
    "        ])\n",
    "record.add_field(title, author)\n",
    "\n",
    "\n",
    "# write the MARC record to disk\n",
    "with open('test_write.dat', 'wb') as out:\n",
    "    out.write(record.as_marc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what does it look like\n",
    "print(record.as_marc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ugh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_test = []\n",
    "\n",
    "# open the file \n",
    "with open(\"test_write.dat\", \"rb\") as fileh:\n",
    "    \n",
    "    # create an isntance of the marc reader, like with CSV \n",
    "    marc_reader = pymarc.MARCReader(fileh)\n",
    "    \n",
    "    # loop over each record\n",
    "    for record in marc_reader:\n",
    "        # add record to our list\n",
    "        records_test.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the title and author of the record we read from disk\n",
    "print(records_test[0].title(), \"by\", records_test[0].author())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hi MARC](https://media.giphy.com/media/G2vaqcEICxOyA/giphy.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
